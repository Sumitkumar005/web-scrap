{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"v2-complete-ambitio-uni-data-extraction-steps (1) 1.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1maR-ZxJw6EPpJwKN3pLrNp8nCFz7GVcu\n",
    "\"\"\"\n",
    "\n",
    "!pip install beautifulsoup4\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "from typing import Dict, List, Any, Optional\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Section 1: Configuration Variables\n",
    "API_CONFIG = {\n",
    "    'API_TOKEN': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNzU3NDg5ODg3LCJpYXQiOjE3NTcwNTc4ODYsImp0aSI6ImQ0NWVhNTI4MTZhNjQwZTI4ZGQ3NWZmYzliZWExNThhIiwidXNlcl9pZCI6MjMxMDV9.g4wYgpuwh1kizOIHc_8Br0C9ehXuvtLFYM3_TOmI2Do',  # Replace with new token\n",
    "    'CARD_API_URL': 'https://apis.ambitio.in/api/programs/explore',\n",
    "    'DETAIL_API_URL': 'https://dashboard.ambitio.club/api/programs/college',\n",
    "    'HEADERS': {\n",
    "        'Authorization': '',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "}\n",
    "\n",
    "UNIVERSITY_CONFIG = {\n",
    "    'LIST': [\"Harvard University\", \"Stanford University\", \"Massachusetts Institute of Technology\"],\n",
    "    'NAME': \"\",  # dynamic\n",
    "    'COURSE_TYPE': 'Master',\n",
    "    'COUNTRY': 'US'\n",
    "}\n",
    "\n",
    "FILE_CONFIG = {\n",
    "    'CSV_OUTPUT': 'universities_logo_gallery.csv',\n",
    "}\n",
    "\n",
    "PROCESSING_CONFIG = {\n",
    "    'REQUEST_DELAY': 2,\n",
    "    'MAX_RETRIES': 3\n",
    "}\n",
    "\n",
    "SCHEMA_CONFIG = {\n",
    "    'CSV_HEADERS': [\n",
    "        'uni_name', 'university_logo_url', 'gallery_urls'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Section 2: Utility Functions\n",
    "def setup_api_headers():\n",
    "    \"\"\"Configure API headers with authentication\"\"\"\n",
    "    API_CONFIG['HEADERS']['Authorization'] = f\"Bearer {API_CONFIG['API_TOKEN']}\"\n",
    "\n",
    "def handle_api_response(response: requests.Response) -> Dict:\n",
    "    \"\"\"Common handler for API responses\"\"\"\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def save_json_file(data: Any, filename: str):\n",
    "    \"\"\"Generic JSON file saver\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "def load_json_file(filename: str) -> Any:\n",
    "    \"\"\"Generic JSON file loader\"\"\"\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_gallery_urls(uni_name: str) -> List[str]:\n",
    "    \"\"\"Scrape gallery image URLs from university page\"\"\"\n",
    "    slug = uni_name.lower().replace(' ', '-')\n",
    "    url = f\"https://ambitio.club/college/{slug}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=API_CONFIG['HEADERS'])\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        gallery_urls = []\n",
    "        for img in soup.find_all('img'):\n",
    "            src = img.get('src', '')\n",
    "            if 'gallery-images' in src or 'university/gallery' in src:\n",
    "                if src.startswith('//'):\n",
    "                    src = 'https:' + src\n",
    "                elif src.startswith('/'):\n",
    "                    src = 'https://ambitio.club' + src\n",
    "                gallery_urls.append(src)\n",
    "        return gallery_urls\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_image(url: str, path: str):\n",
    "    \"\"\"Download image from URL to path\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True, headers=API_CONFIG['HEADERS'])\n",
    "        response.raise_for_status()\n",
    "        with open(path, 'wb') as f:\n",
    "            for chunk in response.iter_content(8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded {url} to {path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "# Section 3: Data Extraction Pipeline\n",
    "class CardDataExtractor:\n",
    "    \"\"\"Handles extraction of initial card data\"\"\"\n",
    "\n",
    "    def fetch_cards(self) -> Optional[Dict]:\n",
    "        \"\"\"Fetch card data from API\"\"\"\n",
    "        params = {\n",
    "            'offset': 0,\n",
    "            'limit': 128,\n",
    "            'university': UNIVERSITY_CONFIG['NAME'],\n",
    "            'courseType': UNIVERSITY_CONFIG['COURSE_TYPE']\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                API_CONFIG['CARD_API_URL'],\n",
    "                headers=API_CONFIG['HEADERS'],\n",
    "                params=params\n",
    "            )\n",
    "            return handle_api_response(response)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching cards: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_cards(self, data: Dict):\n",
    "        \"\"\"Process and save card data\"\"\"\n",
    "        filename = f\"{UNIVERSITY_CONFIG['NAME'].replace(' ', '_')}_ambitio_card_data_master.json\"\n",
    "        save_json_file(data, filename)\n",
    "\n",
    "class CourseDataExtractor:\n",
    "    \"\"\"Handles extraction of detailed course data\"\"\"\n",
    "\n",
    "    def extract_course_ids(self, card_data: Dict) -> List[str]:\n",
    "        \"\"\"Extract course IDs from card data\"\"\"\n",
    "        return [str(item['id']) for item in card_data['data']['results']]\n",
    "\n",
    "    def fetch_course_details(self, course_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Fetch detailed course data\"\"\"\n",
    "        detailed_data = []\n",
    "\n",
    "        for cid in course_ids:\n",
    "            time.sleep(PROCESSING_CONFIG['REQUEST_DELAY'])\n",
    "            payload = {\"id\": cid}\n",
    "\n",
    "            try:\n",
    "                response = requests.put(\n",
    "                    API_CONFIG['DETAIL_API_URL'],\n",
    "                    headers=API_CONFIG['HEADERS'],\n",
    "                    json=payload\n",
    "                )\n",
    "                data = handle_api_response(response)\n",
    "                detailed_data.append(data)\n",
    "                print(f\"Successfully fetched data for ID {cid}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error fetching details for ID {cid}: {e}\")\n",
    "\n",
    "        return detailed_data\n",
    "\n",
    "class DataPipeline:\n",
    "    \"\"\"Main pipeline orchestrator\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.card_extractor = CardDataExtractor()\n",
    "        self.course_extractor = CourseDataExtractor()\n",
    "\n",
    "    def run_extraction(self):\n",
    "        \"\"\"Execute pipeline for universities\"\"\"\n",
    "        setup_api_headers()\n",
    "        uni_rows = []\n",
    "        for name in UNIVERSITY_CONFIG['LIST']:\n",
    "            UNIVERSITY_CONFIG['NAME'] = name\n",
    "            print(f\"Processing {name}...\")\n",
    "            card_data = self.card_extractor.fetch_cards()\n",
    "            if not card_data or not card_data.get('data', {}).get('results'):\n",
    "                print(f\"No data for {name}\")\n",
    "                continue\n",
    "            self.card_extractor.process_cards(card_data)\n",
    "            course_ids = self.course_extractor.extract_course_ids(card_data)[:1]\n",
    "            details = self.course_extractor.fetch_course_details(course_ids)\n",
    "            if not details:\n",
    "                continue\n",
    "            data = details[0].get('data', {})\n",
    "            university = data.get('university', {})\n",
    "            uni_name = university.get('name', name)\n",
    "            # Logo: check API, fallback to construct\n",
    "            logo_path = university.get('logo', '')  # Adjust key if different\n",
    "            if logo_path:\n",
    "                university_logo_url = f\"https://ambitio-django-backend-media.s3.amazonaws.com/{logo_path}\"\n",
    "            else:\n",
    "                slug = uni_name.lower().replace(' ', '-')\n",
    "                university_logo_url = f\"https://ambitio-django-backend-media.s3.amazonaws.com/programs/university/logo/{slug}.jpg\"\n",
    "            # Gallery: scrape\n",
    "            gallery_list = get_gallery_urls(uni_name)\n",
    "            gallery_urls = ','.join(gallery_list) if gallery_list else ''\n",
    "            row = {\n",
    "                'uni_name': uni_name,\n",
    "                'university_logo_url': university_logo_url,\n",
    "                'gallery_urls': gallery_urls\n",
    "            }\n",
    "            uni_rows.append(row)\n",
    "            # Create folders and download\n",
    "            main_folder = os.path.join('/content', uni_name.replace(' ', '_'))\n",
    "            os.makedirs(main_folder, exist_ok=True)\n",
    "            logo_folder = os.path.join(main_folder, 'logo')\n",
    "            os.makedirs(logo_folder, exist_ok=True)\n",
    "            gallery_folder = os.path.join(main_folder, 'gallery')\n",
    "            os.makedirs(gallery_folder, exist_ok=True)\n",
    "            # Download logo\n",
    "            if university_logo_url:\n",
    "                logo_path = os.path.join(logo_folder, 'logo.jpg')\n",
    "                download_image(university_logo_url, logo_path)\n",
    "            # Download gallery\n",
    "            for i, url in enumerate(gallery_list):\n",
    "                img_path = os.path.join(gallery_folder, f'image_{i+1}.jpg')\n",
    "                download_image(url, img_path)\n",
    "        # Write CSV\n",
    "        with open(FILE_CONFIG['CSV_OUTPUT'], 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=SCHEMA_CONFIG['CSV_HEADERS'])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(uni_rows)\n",
    "        print(f\"CSV created at {FILE_CONFIG['CSV_OUTPUT']}\")\n",
    "        print(\"Downloads completed in university folders.\")\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = DataPipeline()\n",
    "    pipeline.run_extraction()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
